{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "janome_tut_03_analyzer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Gg2Pq2Xf3fhw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Analyzer\n",
        "\n",
        "**実行するには，メニューの「PLAYGROUNDで開く」を押してください。（Google アカウントが必要です。）**\n",
        "\n",
        "[ここ](https://colab.research.google.com/drive/1rgBkcz0dhr3L0YsMnIfkDXGcLXcsaC_U) にハンズオンの解答例があります。解答を見る前に，なるべく自分で解いてみてください。\n",
        "\n",
        "## 準備\n",
        "\n",
        "1. Janome をインストール\n",
        "2. IPA フォントの入手とアップロード"
      ]
    },
    {
      "metadata": {
        "id": "hXPMij3E3aVY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install janome"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yif7cIL2gY4S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://ipafont.ipa.go.jp/old/ipafont/download.html から TTFファイル「IPA P ゴシック」をダウンロードして手元で解凍し，`ipagp.ttf` ファイルを Google Colab にアップロード\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "84C1VT0s4lUy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ワードカウント\n",
        "\n",
        "単語の出現回数を数えましょう。\n",
        "\n",
        "参考\n",
        "\n",
        "- https://mocobeta.github.io/janome/#analyzer-v0-3-5\n",
        "- http://mocobeta.github.io/janome/api/janome.html#janome.tokenfilter.TokenCountFilter"
      ]
    },
    {
      "metadata": {
        "id": "zZjtKgPj42Jh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "from janome.analyzer import Analyzer\n",
        "from janome.tokenfilter import *\n",
        "text = u'すもももももももものうち'\n",
        "token_filters = [TokenCountFilter()]\n",
        "a = Analyzer(tokenizer=Tokenizer(), token_filters=token_filters)\n",
        "for k, v in a.analyze(text):\n",
        "  print('%s: %d' % (k, v))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gUc3fgzz5jhs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ハンズオン課題 3-1\n",
        "\n",
        "引数で指定されたファイルを読み，出現回数の多い上位20単語とその出現回数を，出現回数の多い順に返す関数 `wc(file)` を作成してください。"
      ]
    },
    {
      "metadata": {
        "id": "I1ta-0hS6nez",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# janome-tutorial/hands-on/data/kazeno_matasaburo_utf8.txt (他のファイルでもよい) を Google Colab にアップロード\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hSMy6FLi695Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "from janome.analyzer import Analyzer\n",
        "from janome.charfilter import *\n",
        "from janome.tokenfilter import *\n",
        "\n",
        "MAX_WORDS = 20\n",
        "\n",
        "def wc(file):\n",
        "    with open(file, encoding='utf8') as f:\n",
        "        \"\"\"\n",
        "        ここに処理を書く。\n",
        "        戻り値として，(単語, 出現回数) のタプルのリストを返す。\n",
        "        \"\"\"\n",
        "      \n",
        "counts = wc('kazeno_matasaburo_utf8.txt')\n",
        "for k, v in counts:\n",
        "    print('%s\\t%d' % (k, v))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0KudKIkD-o21",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ハンズオン課題 3-2\n",
        "\n",
        "課題 3-1 を修正して，２番めの引数 pos が指定されたら，その品詞に絞り，かつ基本形 (base form) に正規化し，出現回数の多い上位20単語と，その出現回数を出力するようにしてください。"
      ]
    },
    {
      "metadata": {
        "id": "OV7Hxrs6-9wP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "from janome.analyzer import Analyzer\n",
        "from janome.charfilter import *\n",
        "from janome.tokenfilter import *\n",
        "\n",
        "MAX_WORDS = 20\n",
        "\n",
        "def wc(file, pos=[]):\n",
        "    with open(file, encoding='utf8') as f:\n",
        "        \"\"\"\n",
        "        ここに処理を書く。\n",
        "        戻り値として，(単語, 出現回数) のタプルのリストを返す。\n",
        "        \"\"\"\n",
        "        \n",
        "# 名詞と動詞に絞ってカウント\n",
        "counts = wc('kazeno_matasaburo_utf8.txt', ['名詞','動詞'])\n",
        "for k, v in counts:\n",
        "    print('%s\\t%d' % (k, v))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zZveV6unArL2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## カスタムフィルター\n",
        "\n",
        "CharFilter, TokenFilter クラスを拡張して，独自のフィルタ処理を実装できます。\n",
        "\n",
        "\n",
        "(参考) CharFilter の拡張\n",
        "\n",
        "- http://mocobeta.github.io/janome/api/janome.html#module-janome.charfilter\n",
        "- https://github.com/mocobeta/janome/blob/master/janome/charfilter.py\n",
        "\n",
        "(参考) TokenFilter の拡張\n",
        "\n",
        "- http://mocobeta.github.io/janome/api/janome.html#module-janome.tokenfilter\n",
        "- https://github.com/mocobeta/janome/blob/master/janome/tokenfilter.py"
      ]
    },
    {
      "metadata": {
        "id": "NWXl9X2pCBkc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ハンズオン課題 3-3\n",
        "\n",
        "janome.tokenfilter にいくつかの組み込みトークンフィルターがありますが，ストップワードを指定するフィルターがまだありません。\n",
        "\n",
        "以下の仕様で，`StopWordFilter` を作成してください。\n",
        "\n",
        "- 初期化時にストップワードのリストを受け取り，基本形と，いずれかのストップワードが一致したら出力しない。\n",
        "- 可能であれば，ストップワードリストをファイル (1行1ワード) でも受け取れるようにしてください。"
      ]
    },
    {
      "metadata": {
        "id": "Z-WXdsLTCQ9O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# StopWordFilter の実装\n",
        "from janome.tokenizer import Tokenizer\n",
        "from janome.analyzer import Analyzer\n",
        "from janome.charfilter import *\n",
        "from janome.tokenfilter import *\n",
        "\n",
        "class StopWordFilter(TokenFilter):\n",
        "  def __init__(self, word_list=[], word_list_file=''):\n",
        "    \"\"\"\n",
        "    ここに初期化コードを記述\n",
        "    \"\"\"\n",
        "    \n",
        "  def apply(self, tokens):\n",
        "    \"\"\"\n",
        "    ここにフィルター処理を記述\n",
        "    \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FCb8zGQqG-V5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# stop word をリストで指定する\n",
        "token_filters = [StopWordFilter(word_list=['プログラミング'])]\n",
        "a = Analyzer(tokenizer=Tokenizer(), token_filters=token_filters)\n",
        "for token in a.analyze('Pythonは人気の高いプログラミング言語です。'):\n",
        "  print(token)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h4VxIslmHBDt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# stop word をファイルで指定する\n",
        "!echo \"プログラミング\" > stop_words.txt\n",
        "!echo \"Python\" >> stop_words.txt\n",
        "\n",
        "token_filters = [StopWordFilter(word_list_file='stop_words.txt')]\n",
        "a = Analyzer(tokenizer=Tokenizer(), token_filters=token_filters)\n",
        "for token in a.analyze('Pythonは人気の高いプログラミング言語です。'):\n",
        "  print(token)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FJipxZX6inCM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## WordCloud 再考"
      ]
    },
    {
      "metadata": {
        "id": "eKgYRuBiHHiA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ハンズオン課題 3-4\n",
        "\n",
        "課題 2-1 で作った WordCloud は，まだいまいちでした。\n",
        "\n",
        "ここまでの知識（ユーザー辞書や Analyzer）を使って，いい感じの WordCloud を自由に作ってください。WordCloud を見て，それぞれの作品名がぱっとわかるくらいの特徴が出たら素敵です。"
      ]
    },
    {
      "metadata": {
        "id": "M753xVBDIu8D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## write your code ##"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}